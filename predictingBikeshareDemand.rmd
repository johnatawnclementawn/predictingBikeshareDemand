---
title: "Predicting Bikeshare Demand"
author: "Johnathan Clementi"
date: "11/19/2021"
output:
  html_document:
    toc: true
    toc_float:
      collapsed: true
      smooth_scroll: true
    code_folding: hide

---

```{r setup, results='hide'}
knitr::opts_chunk$set(
	error = FALSE,
	message = FALSE,
	warning = FALSE,
	cache = TRUE
)
```


```{r libraries, results='hide'}
library(tidyverse)
library(tidycensus)
library(sf)
library(lubridate)
library(tigris)
library(gganimate)
library(riem)
library(gridExtra)
library(knitr)
library(kableExtra)
library(rmdformats)
library(FNN)


options(tigris_class = "sf")
source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")

palette5 <- c("#eff3ff","#bdd7e7","#6baed6","#3182bd","#08519c")
palette4 <- c("#D2FBD4","#92BCAB","#527D82","#123F5A")
palette2 <- c("#6baed6","#08519c")
```


# 2 Data Wrangling

Capital Bikeshare ride data obtained from this [link](https://s3.amazonaws.com/capitalbikeshare-data/index.html)   
More information about these data can be found at this [link](https://www.capitalbikeshare.com/system-data)
```{r include=FALSE}
# Rideshare data were previously downloaded for April, May, and June of 2019 (Pre-pandemic) from the link above.
root.dir = "D:/Users/Johnathan/Google Drive/Grad School/PennDesign_MUSA/PublicPolicyAnalytics/predictingBikeshareDemand/data"

crs <- 'ESRI:102285' #StatePlane Maryland
```

### Capital Bikeshare Data
```{r results='hide'}
rides <- rbind(#read.csv(file.path(root.dir,"202108-capitalbikeshare-tripdata.csv")),
              read.csv(file.path(root.dir,"202109-capitalbikeshare-tripdata.csv")),
              read.csv(file.path(root.dir,"202110-capitalbikeshare-tripdata.csv"))
              )

rides <- rides %>%
  mutate(started_at = ymd_hms(started_at),
         ended_at = ymd_hms(ended_at),
         interval60 = floor_date(ymd_hms(started_at), unit = "hour"),
         interval15 = floor_date(ymd_hms(started_at), unit = "15 mins"),
         week = week(interval60),
         dotw = wday(interval60, label=TRUE)
        ) %>%
  mutate(weekend = ifelse(dotw %in% c("Sun", "Sat"), "Weekend", "Weekday")) %>%
  mutate(time_of_day = case_when(hour(interval60) < 7 | hour(interval60) > 18 ~ "Overnight",
                                 hour(interval60) >= 7 & hour(interval60) < 10 ~ "AM Rush",
                                 hour(interval60) >= 10 & hour(interval60) < 15 ~ "Mid-Day",
                                 hour(interval60) >= 15 & hour(interval60) <= 18 ~ "PM Rush")
        )

```

```{r pullCensus, results='hide'}
# total pop - B25026_001E
tractsDC <- get_acs(geography = "tract", 
                     variables = c("B01003_001", "B19013_001", 
                                  "B02001_002", "B08013_001",
                                  "B08012_001", "B08301_001", 
                                  "B08301_010", "B01002_001"), 
                     year=2017, 
                     state=11999,
                     geometry=TRUE, 
                     output="wide") %>%
  st_transform(crs = crs) %>%
  rename(Total_Pop =  B01003_001E,
         Med_Inc = B19013_001E,
         Med_Age = B01002_001E,
         White_Pop = B02001_002E,
         Travel_Time = B08013_001E,
         Num_Commuters = B08012_001E,
         Means_of_Transport = B08301_001E,
         Total_Public_Trans = B08301_010E) %>%
  select(Total_Pop, Med_Inc, White_Pop, Travel_Time,
         Means_of_Transport, Total_Public_Trans,
         Med_Age,
         GEOID, geometry) %>%
  mutate(Percent_White = White_Pop / Total_Pop,
         Mean_Commute_Time = Travel_Time / Total_Public_Trans,
         Percent_Taking_Public_Trans = Total_Public_Trans / Means_of_Transport) %>%
  mutate(natMall = case_when(GEOID == "11001006202" ~ 1,
                             GEOID != "11001006202" ~ 0))


rides_tracts <- st_join(rides %>% 
          filter(is.na(start_lng) == FALSE &
                   is.na(start_lat) == FALSE &
                   is.na(end_lat) == FALSE &
                   is.na(end_lng) == FALSE) %>%
          st_as_sf(., coords = c("start_lng", "start_lat"), crs = 4326),
        tractsDC %>%
          st_transform(crs=4326),
        join=st_intersects,
              left = TRUE) %>%
  rename(Origin.Tract = GEOID) %>%
  mutate(start_lng = unlist(map(geometry, 1)),
         start_lat = unlist(map(geometry, 2)))%>%
  as.data.frame() %>%
  select(-geometry)%>%
  st_as_sf(., coords = c("end_lng", "end_lat"), crs = 4326) %>%
  st_join(., tractsDC %>%
            st_transform(crs=4326),
          join=st_intersects,
          left = TRUE) %>%
  rename(Destination.Tract = GEOID)  %>%
  mutate(end_lng = unlist(map(geometry, 1)),
         end_lat = unlist(map(geometry, 2)))%>%
  as.data.frame() %>%
  select(-geometry)

```


```{r colleges, results='hide'}
colleges <- st_read("https://opendata.arcgis.com/datasets/0d7bedf9d582472e9ff7a6874589b545_0.geojson") %>%
  st_transform(crs = crs) 

# Help doc for this code: https://www.py4u.net/discuss/871336
colleges$indicator <- st_intersects(colleges, tractsDC) %>% lengths > 0

colleges <- colleges %>%
  filter(indicator == TRUE) %>%
  select(-indicator)
```


```{r docks, results='hide'}
# Retrieve location data for Capital Bikeshare dock locations
# Remove regions except for Washington DC because we don't have the computational resources for analyzing the entire population of bikeshare locations
# Why do station_id's not match up?????
docks <- st_read("https://opendata.arcgis.com/datasets/a1f7acf65795451d89f0a38565a975b3_5.geojson") %>%
  st_transform(crs) %>%
  dplyr::select(OBJECTID, LATITUDE, LONGITUDE, NAME, CAPACITY, REGION_NAME) %>%
  filter(REGION_NAME == "Washington, DC") %>%
  mutate(nn_college = nn_function(st_coordinates(.), st_coordinates(colleges), 1))

docks_Geom <- docks %>%
  as.data.frame() %>%
  distinct(NAME, .keep_all = TRUE) %>%
  select(NAME, geometry) %>% 
  st_sf

```



### 2.1 Filter rides without stations
```{r}

rides <- dplyr::left_join(rides, docks %>% st_drop_geometry(), by =c("start_station_name" = "NAME")) %>%
            select(-LONGITUDE, - LATITUDE, -OBJECTID, -REGION_NAME) %>%
            rename(start_station_capacity = CAPACITY,
                   start_station_nnCollege = nn_college) %>%
            na.omit()

rides <- dplyr::left_join(rides, docks %>% st_drop_geometry(), by =c("end_station_name" = "NAME")) %>%
            select(-LONGITUDE, - LATITUDE, -OBJECTID) %>%
            rename(end_station_capacity = CAPACITY,
                   end_station_nnCollege = nn_college) %>%
            na.omit()


rides_tracts <- dplyr::left_join(rides_tracts, docks %>% st_drop_geometry(), by =c("start_station_name" = "NAME")) %>%
            select(-LONGITUDE, - LATITUDE, -OBJECTID, -REGION_NAME) %>%
            rename(start_station_capacity = CAPACITY,
                   start_station_nnCollege = nn_college) %>%
            na.omit()

rides_tracts <- dplyr::left_join(rides_tracts, docks %>% st_drop_geometry(), by =c("end_station_name" = "NAME")) %>%
            select(-LONGITUDE, - LATITUDE, -OBJECTID) %>%
            rename(end_station_capacity = CAPACITY,
                   end_station_nnCollege = nn_college) %>%
            na.omit()

```

### 2.2 Weather Data
```{r fig.width=12, fig.height= 10}
# riem_networks <- riem_networks()
# vaStations <- riem_stations("VA_ASOS") %>%
#   st_as_sf(coords = c("lon","lat"), crs=crs)
# mdStations <- riem_stations("MD_ASOS") %>%
#   st_as_sf(coords = c("lon","lat"), crs=crs)
# The closest weather station to our study area is at Reagan National Airport - "DCA"

weather.Data <- 
  riem_measures(station = "DCA", date_start = "2021-09-01", date_end = "2021-10-31")

weather.Panel <-  
  weather.Data %>%
    mutate_if(is.character, list(~replace(as.character(.), is.na(.), "0"))) %>% 
    replace(is.na(.), 0) %>%
    mutate(interval60 = ymd_h(substr(valid, 1, 13))) %>%
    mutate(week = week(interval60),
           dotw = wday(interval60, label=TRUE)) %>%
    group_by(interval60) %>%
    summarize(Temperature = max(tmpf),
              Precipitation = sum(p01i),
              Wind_Speed = max(sknt)) %>%
    mutate(Temperature = ifelse(Temperature == 0, 42, Temperature))

grid.arrange(top = "Weather Data - Washington, DC - September - October, 2021",
  ggplot(weather.Panel, aes(interval60, Precipitation)) + geom_line() + 
    labs(title="Precipitation", x="Hour", y="Precipitation") + plotTheme(),
  ggplot(weather.Panel, aes(interval60,Wind_Speed)) + geom_line() + 
    labs(title="Wind Speed", x="Hour", y="Wind Speed") + plotTheme(),
  ggplot(weather.Panel, aes(interval60,Temperature)) + geom_line() + 
    labs(title="Temperature", x="Hour", y="Temperature") + plotTheme())
```


# 3 Visualizations

### 3.1 View ridership over time
```{r fig.width=12, fig.height=6}
precipHours <- weather.Panel %>%
  filter(Precipitation > 0.1) %>%
  mutate(precip = "Over0.1")

ggplot(rides %>%
       group_by(interval60) %>% tally())+
  geom_line(aes(x = interval60, y = n), size = 0.5) +
  geom_vline(data = precipHours, aes(xintercept = interval60), color = "blue", linetype = "dotted") +
  labs(title="Capital Bikeshare trips per hr. Washington, DC, September-October 2021",
       x="Date", 
       y="Number of trips",
       caption = "Blue dotted lines indicate hours with more than 0.1 inches of precip.") +

  plotTheme()

```

```{r fig.width=12, fig.height=6}
rides %>%
  group_by(interval60, start_station_name, time_of_day) %>%
         tally() %>%
  filter(n < 25) %>%
  group_by(start_station_name, time_of_day) %>%
  summarize(mean_trips = mean(n)) %>%
  ggplot() +
    geom_histogram(aes(mean_trips), binwidth = 1)+
    labs(title="Mean Number of Hourly Trips Per Station. Washington DC, September-October, 2021",
         x="Number of trips", 
         y="Frequency")+
    facet_wrap(~factor(time_of_day,levels=c("AM Rush", "Mid-Day", "PM Rush", "Overnight"))) +
  plotTheme()
```


```{r}
ggplot(rides %>%
         group_by(interval60, start_station_name) %>%
         tally())+
  geom_histogram(aes(n), binwidth = 5)+
  labs(title="Capital Bikeshare trips per hr by station. Washington DC, September-October, 2021",
       x="Trip Counts", 
       y="Number of Stations")+
  plotTheme()
```

```{r fig.width=10}
ggplot(rides) +
  geom_freqpoly(aes(hour(started_at), color = dotw), size = 1, binwidth = 1) +
  scale_color_brewer(palette = "Reds") +
  labs(title="Capital Bikeshare trips by day of the week in Washington DC, September-October, 2021",
       x="Hour", 
       y="Trip Counts") +
  plotTheme() 


ggplot(rides %>% mutate(weekend = ifelse(dotw %in% c("Sun", "Sat"), "Weekend", "Weekday"))) +
  geom_freqpoly(aes(hour(started_at), color = weekend), size = 1, binwidth = 1) +
  labs(title="Capital Bikeshare trips by weekday vs weekend in Washington DC, September-October, 2021",
       x="Hour", 
       y="Trip Counts") +
  plotTheme()
```

```{r origin_map, fig.width=12, fig.height=12}
grid.arrange(nrow = 2,
  ggplot()+
    geom_sf(data = tractsDC) +
    geom_sf(data = rides %>%
              group_by(start_station_id, start_station_name, weekend, time_of_day) %>%
              tally() %>%
              left_join(., docks, by =c("start_station_name" = "NAME")) %>%
              st_sf(),
            aes(color = n),
            fill = "transparent", alpha = 0.6, size = 1)+
    scale_colour_viridis_c(direction = 1, option = "magma")+
    # ylim(min(rides$start_lat), max(rides$start_lat))+
    # xlim(min(rides$start_lng), max(rides$start_lng))+
    facet_grid(weekend ~ time_of_day)+
    labs(title="Capital Bikeshare trip origins per hr by station. Washington DC, September-October, 2021") +
    mapTheme(),
  ggplot()+
    geom_sf(data = tractsDC) +
    geom_sf(data = rides %>%
              group_by(end_station_id, end_station_name, weekend, time_of_day) %>%
              tally() %>%
              left_join(., docks, by =c("end_station_name" = "NAME")) %>%
              st_sf(),
            aes(color = n),
            fill = "transparent", alpha = 0.6, size = 1)+
    scale_colour_viridis_c(direction = 1, option = "magma")+
    # ylim(min(rides$start_lat), max(rides$start_lat))+
    # xlim(min(rides$start_lng), max(rides$start_lng))+
    facet_grid(weekend ~ time_of_day)+
    labs(title="Capital Bikeshare trip destinations per hr by station. Washington DC, September-October, 2021") +
    mapTheme()
)
```


### 2.3 Create space/time panel
```{r}
length(unique(rides$interval60)) * length(unique(rides$start_station_id))

study.panel <- 
  expand.grid(interval60 = unique(rides$interval60), 
              start_station = unique(rides$start_station_id)) %>%
  left_join(., rides %>%
              select(start_station_id, start_station_name, start_lng, start_lat) %>%
              distinct() %>%
              group_by(start_station_id) %>%
              slice(1), by = c("start_station" = "start_station_id"))

ride.panel <- 
  left_join(ride.panel, chicagoCensus %>%
              as.data.frame() %>%
              select(-geometry), by = c("Origin.Tract" = "GEOID"))

nrow(study.panel)

ride.panel <- rides %>%
  mutate(Trip_Counter = 1) %>%
  right_join(study.panel) %>% 
  group_by(interval60, start_station_id, start_station_name, start_lng, start_lat) %>%
  summarize(Trip_Count = sum(Trip_Counter, na.rm=T)) %>%
  left_join(weather.Panel) %>%
  ungroup() %>%
  filter(is.na(start_station_id) == FALSE) %>%
  mutate(week = week(interval60),
         dotw = wday(interval60, label = TRUE))
```

### .4 Create Time Lags
```{r}
ride.panel <- ride.panel %>% 
  arrange(start_station_id, interval60) %>% 
  mutate(lagHour = dplyr::lag(Trip_Count,1),
         lag2Hours = dplyr::lag(Trip_Count,2),
         lag3Hours = dplyr::lag(Trip_Count,3),
         lag4Hours = dplyr::lag(Trip_Count,4),
         lag12Hours = dplyr::lag(Trip_Count,12),
         lag1day = dplyr::lag(Trip_Count,24)) %>%
  mutate(day = yday(interval60))
```


```{r}
as.data.frame(ride.panel) %>%
    group_by(interval60) %>% 
    summarise_at(vars(starts_with("lag"), "Trip_Count"), mean, na.rm = TRUE) %>%
    gather(Variable, Value, -interval60, -Trip_Count) %>%
    mutate(Variable = factor(Variable, levels=c("lagHour","lag2Hours","lag3Hours","lag4Hours",
                                                "lag12Hours","lag1day")))%>%
    group_by(Variable) %>%  
    summarize(correlation = round(cor(Value, Trip_Count),2))
```


## 4.1. Run Models

```{r train_test}
ride.Train <- filter(ride.panel, week <= 40)
ride.Test <- filter(ride.panel, (week > 40) & (week <= 42))
```

```{r five_models }
# Temporal Only
reg1 <- 
  lm(Trip_Count ~  hour(interval60) + dotw + Temperature,  data=ride.Train)

# Spatial Only
reg2 <- 
  lm(Trip_Count ~  start_station_name + dotw + Temperature,  data=ride.Train)

# Spatiotemporal
reg3 <- 
  lm(Trip_Count ~  start_station_name + hour(interval60) + dotw + Temperature + Precipitation, 
     data=ride.Train)

# Time lagged
reg4 <- 
  lm(Trip_Count ~  start_station_name +  hour(interval60) + dotw + Temperature + Precipitation +
                   lagHour + lag2Hours +lag3Hours + lag12Hours + lag1day, 
     data=ride.Train)
```

## Test data predictions
```{r}
ride.Test.weekNest <- 
  ride.Test %>%
  nest(-week) 

model_pred <- function(dat, fit){
   pred <- predict(fit, newdata = dat)}


week_predictions <- 
  ride.Test.weekNest %>% 
    mutate(ATime_FE = map(.x = data, fit = reg1, .f = model_pred),
           BSpace_FE = map(.x = data, fit = reg2, .f = model_pred),
           CTime_Space_FE = map(.x = data, fit = reg3, .f = model_pred),
           DTime_Space_FE_timeLags = map(.x = data, fit = reg4, .f = model_pred)) %>% 
    gather(Regression, Prediction, -data, -week) %>%
    mutate(Observed = map(data, pull, Trip_Count),
           Absolute_Error = map2(Observed, Prediction,  ~ abs(.x - .y)),
           MAE = map_dbl(Absolute_Error, mean, na.rm = TRUE),
           sd_AE = map_dbl(Absolute_Error, sd, na.rm = TRUE))

```

